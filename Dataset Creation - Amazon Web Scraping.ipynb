{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ccbea53",
   "metadata": {},
   "source": [
    "# Dataset Creation - Amazon Web Scraping\n",
    "- **Overview**: \n",
    "    - This projects focuses on creating a dataset for price of a single product fluctuating overtime\n",
    "    - It starts with **Connecting and Scrapping HTML from Amazon** and storing things into variable, while cleaning it.\n",
    "    - It also holds a script which automates the process to run the data once every day and then stores the Name, Price and Date (the script ran) into an excel file\n",
    "- **Functions and Libraries used**\n",
    "    - BeautifulSoup\n",
    "    - requests\n",
    "    - time\n",
    "    - datetime\n",
    "    - csv\n",
    "    - pandas\n",
    "\n",
    "# Output\n",
    "- Clean Dataset with product and it's updated pricing at per day basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "02ddc17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d989c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           2020 Apple iMac (27-Inch, 3.3GHz 6-Core 10th-Generation Intel Core I5 Processor, 8GB RAM, 512GB SSD) - English\n",
      "          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            $2,449.99\n",
      "           \n",
      "\n",
      "\n",
      "             $\n",
      "            \n",
      "\n",
      "             2,449\n",
      "             \n",
      "              .\n",
      "             \n",
      "\n",
      "\n",
      "             99\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Connecting to Website\n",
    "\n",
    "URL = 'https://www.amazon.ca/Apple-27-inch-10th-Generation-Intel-Core-Processor/dp/B08F8HK6KF/ref=sr_1_6?crid=1RM2LE7P12X31&keywords=imac&qid=1672001818&sprefix=%2Caps%2C464&sr=8-6'\n",
    "\n",
    "# Get headers from http://httpbin.org/get\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Edg/108.0.1462.54\",\n",
    "     \"Accept-Encoding\": \"gzip, deflate\", \n",
    "     \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\", \n",
    "     \"Connection\":\"close\",\n",
    "    \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "page = requests.get(URL, headers=headers)\n",
    "\n",
    "soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\") # makes the pulled content readable\n",
    "\n",
    "title = soup2.find(id='productTitle').get_text() # Inspect and check what you want, we wanted product title \n",
    "price = soup2.find(id='corePriceDisplay_desktop_feature_div').get_text() # the number we get is split in price and decimal\n",
    "\n",
    "print (title)\n",
    "print(price)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "653b8f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 Apple iMac (27-Inch, 3.3GHz 6-Core 10th-Generation Intel Core I5 Processor, 8GB RAM, 512GB SSD) - English\n",
      "2,449.99\n",
      "2022-12-25\n"
     ]
    }
   ],
   "source": [
    "# Cleaning the data - since we are making a dataset\n",
    "\n",
    "title = title.strip()\n",
    "\n",
    "\n",
    "#print (price)\n",
    "price = price.split() # so we split the string and we choose the whole price \n",
    "#print (price)\n",
    "price = price[0].replace('$','') # and remove the Dollar sign since we need to add it in excel for dataset\n",
    "\n",
    "\n",
    "print (title)\n",
    "print (price)\n",
    "type(title)\n",
    "\n",
    "# importing date for when we got the data\n",
    "today= datetime.date.today()\n",
    "\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1abed449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing scrapped stuff into CSV for creating a dataset\n",
    "\n",
    "header = ['Title', 'Price', 'Date']\n",
    "data = [title, price, today]\n",
    "\n",
    "with open('AmazonWebScraperDataset.csv','w', newline ='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerow(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2625eb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title     Price        Date\n",
      "0  2020 Apple iMac (27-Inch, 3.3GHz 6-Core 10th-G...  2,449.99  2022-12-25\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\sunraj\\Desktop\\Web scraper - Amazon\\AmazonWebScraperDataset.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b245be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendig the data in csv\n",
    "\n",
    "with open('AmazonWebScraperDataset.csv','a+', newline ='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2cfc4a",
   "metadata": {},
   "source": [
    "# Automating process\n",
    "- To automate the process we create a function which we add to a timer function to call it periodically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac87959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_price():\n",
    "    URL = 'https://www.amazon.ca/Apple-27-inch-10th-Generation-Intel-Core-Processor/dp/B08F8HK6KF/ref=sr_1_6?crid=1RM2LE7P12X31&keywords=imac&qid=1672001818&sprefix=%2Caps%2C464&sr=8-6'\n",
    "\n",
    "    # Get headers from http://httpbin.org/get\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Edg/108.0.1462.54\",\n",
    "         \"Accept-Encoding\": \"gzip, deflate\", \n",
    "         \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\", \n",
    "         \"Connection\":\"close\",\n",
    "        \"Upgrade-Insecure-Requests\":\"1\"}\n",
    "\n",
    "    page = requests.get(URL, headers=headers)\n",
    "\n",
    "    soup1 = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    soup2 = BeautifulSoup(soup1.prettify(), \"html.parser\") # makes the pulled content readable\n",
    "\n",
    "    title = soup2.find(id='productTitle').get_text() # Inspect and check what you want, we wanted product title \n",
    "    price = soup2.find(id='corePriceDisplay_desktop_feature_div').get_text() # the number we get is split in price and decimal\n",
    "    \n",
    "    \n",
    "    # Cleaning the data - since we are making a dataset\n",
    "    title = title.strip()\n",
    "    \n",
    "    price = price.split() # so we split the string and we choose the whole price \n",
    "   \n",
    "    price = price[0].replace('$','') # and remove the Dollar sign since we need to add it in excel for dataset\n",
    "\n",
    "    # importing date for when we got the data\n",
    "    today= datetime.date.today()\n",
    "    \n",
    "    # Writing scrapped stuff into CSV for creating a dataset\n",
    "    header = ['Title', 'Price', 'Date']\n",
    "    data = [title, price, today]\n",
    "    \n",
    "    # Appendig the data in csv\n",
    "\n",
    "    with open('AmazonWebScraperDataset.csv','a+', newline ='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b495a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a timmer - to create a dataset, and to run the function after fixed intervals\n",
    "    # just make sure to re-run this after restarting your device or loosing the connection\n",
    "    # Only run the script that creats the header once\n",
    "    \n",
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(86400) #time is in seconds, and this is 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "69900223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title     Price        Date\n",
      "0  2020 Apple iMac (27-Inch, 3.3GHz 6-Core 10th-G...  2,449.99  2022-12-25\n",
      "1  2020 Apple iMac (27-Inch, 3.3GHz 6-Core 10th-G...  2,449.99  2022-12-25\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\sunraj\\Desktop\\Web scraper - Amazon\\AmazonWebScraperDataset.csv\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
